{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import linmodules as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del pd.DataFrame.lmodels\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd.api.extensions.register_dataframe_accessor(\"lmodels\")\n",
    "class LinearModels:\n",
    "    def __init__(self, pandas_obj) -> pd.DataFrame:\n",
    "        self._df = pandas_obj\n",
    "        \n",
    "    def multilinear(self, xcols, ycol) -> np.array:\n",
    "        \"\"\"\n",
    "            This function retrieves variables attributed to a train test split with sklearn.model_selection\n",
    "            Args: xcols = the names of x columns to use in our multilinear models as predictors of ycol (passed as a list if it is plural),\n",
    "                  ycol = the variable to predict from dataframe\n",
    "            Output: (y_test, y_pred) the adjusted values to our linear model, from these we can retrieve a residual plot.\n",
    "        \"\"\"\n",
    "        # Data pipeline\n",
    "        X = self._df[xcols].values\n",
    "        y = self._df[[ycol]].values\n",
    "        \n",
    "        # Normalize data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        sc_x = StandardScaler().fit(X)\n",
    "        sc_y = StandardScaler().fit(y)\n",
    "        \n",
    "        # Selecting data\n",
    "        X_train = sc_x.transform(X_train)\n",
    "        X_test  = sc_x.transform(X_test)\n",
    "        y_train = sc_y.transform(y_train)\n",
    "        y_test  = sc_y.transform(y_test)\n",
    "        \n",
    "        # Training the model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        return sc_x, sc_y, model, y_test, y_pred\n",
    "    \n",
    "    def single_linear(self, xcol, ycol) -> np.array:\n",
    "        \"\"\"\n",
    "            This function retrieves variables attributed to a train test split with sklearn.model_selection\n",
    "            \n",
    "            Args: xcols = the name of x column to use in our single linear models as predictors of ycol,\n",
    "                  ycol = the variable to predict from dataframe.\n",
    "                  \n",
    "            Output: (y_test, y_pred) the adjusted values to our linear model, from these we can retrieve a residual plot.\n",
    "        \"\"\"\n",
    "        # Data pipeline\n",
    "        X = self._df[xcol].values.reshape(-1,1)\n",
    "        y = self._df[ycol].values.reshape(-1,1)\n",
    "        \n",
    "        # Normalize data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        sc_x = StandardScaler().fit(X)\n",
    "        sc_y = StandardScaler().fit(y)\n",
    "        \n",
    "        # Selecting data\n",
    "        X_train = sc_x.transform(X_train)\n",
    "        X_test  = sc_x.transform(X_test)\n",
    "        y_train = sc_y.transform(y_train)\n",
    "        y_test  = sc_y.transform(y_test)\n",
    "        \n",
    "        # Training the model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        return sc_x, sc_y, model, y_test, y_pred\n",
    "    \n",
    "    def linear_adjust_plot(self, xcol, ycol, **plot_dict) -> plt.plot: \n",
    "        \"\"\"\n",
    "            This function plots a linear regression embedded in the original x, y scatterplot to observe graphically how accurate is our model.\n",
    "            \n",
    "            Parameters\n",
    "            ------------\n",
    "            x_col: 1D x value we want to use as predictor,\n",
    "            y_col: 1D y value we want to predict,\n",
    "            **plot_dict: values used to give more context to our plot as xlabel, ylabel, and title.\n",
    "            \n",
    "        \"\"\"  \n",
    "        X = self._df[xcol].values.reshape(-1,1)\n",
    "        Y = self._df[ycol].values.reshape(-1,1)\n",
    "\n",
    "        # Normalizing values\n",
    "        X_sc = StandardScaler()\n",
    "        Y_sc = StandardScaler()\n",
    "\n",
    "        X_std = X_sc.fit_transform(X)\n",
    "        Y_std = Y_sc.fit_transform(Y)\n",
    "\n",
    "        # Training model\n",
    "        slr = LinearRegression()\n",
    "        slr.fit(X_std, Y_std)\n",
    "\n",
    "        # Plotting the normalized linear adjust\n",
    "        lm.lin_regplot(X_std, Y_std, slr)\n",
    "        try:\n",
    "            plt.title(label=plot_dict[\"title\"])\n",
    "            plt.xlabel(xlabel=plot_dict[\"xlabel_name\"])\n",
    "            plt.ylabel(ylabel=plot_dict[\"ylabel_name\"])\n",
    "        except KeyError:\n",
    "            pass\n",
    "        plt.tight_layout()\n",
    "        plt.grid(alpha=0.4)\n",
    "        plt.show()\n",
    "        \n",
    "    def ols_model(self, x_cols, y_col) -> set:\n",
    "        \"\"\"\n",
    "            This method is used to create a linear or multilinear ordinary least squares (OLS) regression model to a dataframe given a set of given\n",
    "            x variables, and a y variable to predict.\n",
    "            \n",
    "            Args: x_cols, pd.columns that come from analyzed dataframe, in case of being multilinear, argument should be provided as a list. \n",
    "            y_col, pd.column variable to predict.\n",
    "            \n",
    "            Return: model.\n",
    "        \"\"\"\n",
    "        # Init variables.\n",
    "        try:\n",
    "            X = self._df[x_cols].values\n",
    "            y = self._df[y_col].values\n",
    "        except KeyError:\n",
    "            print(\"Enter your x_cols as a list, in case of being multivariate.\")\n",
    " \n",
    "        if (X.ndim == 1):\n",
    "            X = X.reshape(-1,1)\n",
    "        elif (y.ndim == 1):\n",
    "            y = y.reshape(-1,1)\n",
    "        else:\n",
    "            X = X\n",
    "            y = y\n",
    "                   \n",
    "        # Normalizing variables.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        sc_x = StandardScaler().fit(X)\n",
    "        sc_y = StandardScaler().fit(y)\n",
    "        \n",
    "        X_train = sc_x.transform(X_train)\n",
    "        X_test  = sc_x.transform(X_test)\n",
    "        y_train = sc_y.transform(y_train)\n",
    "        y_test  = sc_y.transform(y_test)\n",
    "        \n",
    "        # Testing the model.\n",
    "        X_train_sm = sm.add_constant(X_train)\n",
    "        X_test_sm  = sm.add_constant(X_test)\n",
    "        \n",
    "        model_ols = sm.OLS(y_train, X_train_sm)\n",
    "        results_ols = model_ols.fit()\n",
    "\n",
    "        return sc_x, sc_y, X_test_sm, results_ols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "missing_values",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
